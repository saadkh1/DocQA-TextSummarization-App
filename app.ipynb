{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoiJk1wmV1wT"
      },
      "outputs": [],
      "source": [
        "!pip install langchain transformers streamlit sentence_transformers faiss-cpu streamlit_chat pypdf unstructured llama-cpp-python==0.1.78 git+https://github.com/openai/whisper.git pytube pytesseract pillow setuptools-rust"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
      ],
      "metadata": {
        "id": "H07WIhvqV5AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_1.bin\n",
        "!wget https://huggingface.co/TheBloke/llama-2-13B-German-Assistant-v2-GGML/resolve/main/llama-2-13b-german-assistant-v2.ggmlv3.q4_0.bin"
      ],
      "metadata": {
        "id": "34ERg6HRWBhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import os\n",
        "import re\n",
        "from PIL import Image\n",
        "import requests\n",
        "import pytesseract\n",
        "from pytube import YouTube\n",
        "import whisper\n",
        "import streamlit as st\n",
        "\n",
        "from streamlit_chat import message\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import (\n",
        "    DirectoryLoader,\n",
        "    PyPDFLoader,\n",
        "    TextLoader,\n",
        "    Docx2txtLoader,\n",
        "    UnstructuredMarkdownLoader,\n",
        "    UnstructuredHTMLLoader,\n",
        ")\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import LlamaCpp\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Constants\n",
        "DB_FAISS_PATH = \"vectorstore/db_faiss\"\n",
        "ENGLISH_MODEL_PATH = \"llama-2-7b-chat.ggmlv3.q4_1.bin\"\n",
        "GERMAN_MODEL_PATH =\"llama-2-13b-german-assistant-v2.ggmlv3.q4_0.bin\"\n",
        "MODEL_EMBEDDING_PATH = \"all-MiniLM-L6-v2\"\n",
        "DATA_DIR = \"data\"\n",
        "\n",
        "class DocumentQAApp:\n",
        "    def __init__(self):\n",
        "        self.selected_language = \"English\"  # Default to English\n",
        "        self.llm = self.load_model()\n",
        "        self.embeddings = self.create_huggingface_embeddings()\n",
        "        self.run_chatbot = True  # Checkbox for chatbot (default: checked)\n",
        "        self.run_summarizer = False  # Checkbox for document summarization (default: unchecked)\n",
        "\n",
        "    # Function to save uploaded files\n",
        "    def save_uploaded_file(self, uploaded_file):\n",
        "        \"\"\"\n",
        "        Save an uploaded file to a specified directory.\n",
        "\n",
        "        Args:\n",
        "            uploaded_file (FileUploader): The uploaded file to be saved.\n",
        "        \"\"\"\n",
        "        file_path = os.path.join(DATA_DIR, uploaded_file.name)\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            f.write(uploaded_file.read())\n",
        "        st.sidebar.success(f\"File '{uploaded_file.name}' saved to {DATA_DIR}\")\n",
        "\n",
        "    # Function to save an HTML file from a URL\n",
        "    def save_html_from_url(self, url, data_dir):\n",
        "        \"\"\"\n",
        "        Save an HTML file from a given URL to a specified directory.\n",
        "\n",
        "        Args:\n",
        "            url (str): The URL to the HTML file.\n",
        "            data_dir (str): The directory where the HTML file should be saved.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                # Extract the file name from the URL\n",
        "                file_name = url.split(\"/\")[-1]\n",
        "                file_name = file_name + \".html\"  # Add .html extension\n",
        "                file_path = os.path.join(data_dir, file_name)\n",
        "\n",
        "                # Save the HTML content to the local file\n",
        "                with open(file_path, \"w\", encoding=\"utf-8\") as f:  # Use text mode 'w'\n",
        "                    f.write(response.text)  # Write the HTML content as text\n",
        "\n",
        "                return file_path\n",
        "            else:\n",
        "                st.sidebar.error(f\"Failed to fetch HTML content from {url}. Status code: {response.status_code}\")\n",
        "        except Exception as e:\n",
        "            st.sidebar.error(f\"An error occurred while fetching the HTML content: {str(e)}\")\n",
        "\n",
        "    # Function to perform OCR on uploaded files and save as text\n",
        "    def ocr_and_save_text(self, input_file, output_folder=DATA_DIR):\n",
        "        \"\"\"\n",
        "        Perform OCR on scanned PDFs or images and save the extracted text as a .txt file.\n",
        "\n",
        "        Args:\n",
        "            input_file (str): The path to the input PDF or image file.\n",
        "            output_folder (str): The folder where the output .txt file will be saved. Default is \"data\".\n",
        "\n",
        "        Returns:\n",
        "            str: The path to the saved .txt file.\n",
        "        \"\"\"\n",
        "        # Check if the output folder exists; if not, create it.\n",
        "        if not os.path.exists(output_folder):\n",
        "            os.makedirs(output_folder)\n",
        "\n",
        "        # Extract the title of the document from the input file name.\n",
        "        title = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "        # Perform OCR using pytesseract.\n",
        "        try:\n",
        "            if input_file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "                img = Image.open(input_file)\n",
        "                text = pytesseract.image_to_string(img)\n",
        "            elif input_file.lower().endswith('.pdf'):\n",
        "                text = pytesseract.image_to_string(Image.open(input_file), lang='eng', config='--psm 6')\n",
        "            else:\n",
        "                return None  # Unsupported file format.\n",
        "\n",
        "            # Create the output .txt file path.\n",
        "            txt_file_path = os.path.join(output_folder, f'{title}.txt')\n",
        "\n",
        "            # Save the extracted text to the .txt file.\n",
        "            with open(txt_file_path, 'w', encoding='utf-8') as txt_file:\n",
        "                txt_file.write(text)\n",
        "\n",
        "            # Remove the input image file.\n",
        "            os.remove(input_file)\n",
        "\n",
        "            return txt_file_path\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred during OCR: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    # Function to sanitize a string for use as a filename\n",
        "    def sanitize_filename(self, filename):\n",
        "        \"\"\" Remove characters that are not allowed in filenames\"\"\"\n",
        "        return re.sub(r'[\\/:*?\"<>|]', '_', filename)\n",
        "\n",
        "    # Function to transcribe audio file\n",
        "    def transcribe_audio_file(self, audio_file):\n",
        "        \"\"\"\n",
        "        Transcribe an audio file to text and save the transcription as a .txt file.\n",
        "\n",
        "        Args:\n",
        "            audio_file (FileUploader): The uploaded audio file to be transcribed.\n",
        "\n",
        "        Returns:\n",
        "            str: The path to the saved .txt file containing the transcription.\n",
        "                Returns an empty string in case of an error.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            model = whisper.load_model(\"base\")\n",
        "            audio_title = audio_file.name\n",
        "            safe_audio_title = self.sanitize_filename(audio_title)\n",
        "\n",
        "            # Save the uploaded audio file\n",
        "            audio_path = os.path.join(DATA_DIR, audio_title)\n",
        "            with open(audio_path, \"wb\") as f:\n",
        "                f.write(audio_file.read())\n",
        "\n",
        "            # Transcribe the audio file\n",
        "            transcription = model.transcribe(audio_path)\n",
        "\n",
        "            # Create the output .txt file path\n",
        "            txt_file_path = os.path.join(DATA_DIR, f\"{safe_audio_title}.txt\")\n",
        "\n",
        "            # Save the transcription to the .txt file\n",
        "            with open(txt_file_path, \"w\", encoding=\"utf-8\") as text_file:\n",
        "                text_file.write(transcription[\"text\"])\n",
        "\n",
        "            # Remove the uploaded audio file\n",
        "            os.remove(audio_path)\n",
        "\n",
        "            return txt_file_path\n",
        "        except Exception as e:\n",
        "            return str(e)\n",
        "\n",
        "    # Fonction pour transcrire une vidéo YouTube\n",
        "    def transcribe_youtube_video(self, video_url):\n",
        "        \"\"\"\n",
        "        Transcrit une vidéo YouTube en texte.\n",
        "\n",
        "        Args:\n",
        "            video_url (str): L'URL de la vidéo YouTube à transcrire.\n",
        "\n",
        "        Returns:\n",
        "            str: Le chemin du fichier texte contenant la transcription.\n",
        "                 Retourne une chaîne vide en cas d'erreur.\n",
        "\n",
        "        Raises:\n",
        "            Exception: En cas d'erreur lors du téléchargement ou de la transcription.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            model = whisper.load_model(\"base\")\n",
        "            yt = YouTube(video_url)\n",
        "            video_title = yt.title\n",
        "            safe_video_title = self.sanitize_filename(video_title)\n",
        "            yt.streams.filter(only_audio=True).first().download(filename=\"audio.mp3\")\n",
        "            transcription = model.transcribe(\"audio.mp3\")\n",
        "            output_file = os.path.join(DATA_DIR, f\"{video_title}.txt\")\n",
        "            with open(output_file, \"w\", encoding=\"utf-8\") as text_file:\n",
        "                text_file.write(transcription[\"text\"])\n",
        "            os.remove(\"audio.mp3\")\n",
        "            return output_file\n",
        "        except Exception as e:\n",
        "            return str(e)\n",
        "\n",
        "    # Function to create a vector database\n",
        "    def create_vector_database(self, data_dir):\n",
        "        \"\"\"\n",
        "        Create a vector database from documents in a specified directory.\n",
        "\n",
        "        Args:\n",
        "            data_dir (str): The directory containing documents to be indexed.\n",
        "\n",
        "        Returns:\n",
        "            FAISS: An instance of FAISS (Fast Approximate Nearest Neighbors Index).\n",
        "        \"\"\"\n",
        "        # Load various types of documents from the specified directory\n",
        "        loaders = [\n",
        "            DirectoryLoader(data_dir, glob=\"*.pdf\", loader_cls=PyPDFLoader),\n",
        "            DirectoryLoader(data_dir, glob=\"*.md\", loader_cls=UnstructuredMarkdownLoader),\n",
        "            DirectoryLoader(data_dir, glob=\"*.txt\", loader_cls=TextLoader),\n",
        "            DirectoryLoader(data_dir, glob=\"*.docx\", loader_cls=Docx2txtLoader),\n",
        "            DirectoryLoader(data_dir, glob=\"*.html\", loader_cls=UnstructuredHTMLLoader),\n",
        "        ]\n",
        "\n",
        "        # Load and split documents into chunks for indexing\n",
        "        loaded_documents = [doc for loader in loaders for doc in loader.load()]\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "        chunked_documents = text_splitter.split_documents(loaded_documents)\n",
        "\n",
        "        # Build the vector database\n",
        "        vector_database = FAISS.from_documents(\n",
        "            documents=chunked_documents,\n",
        "            embedding=self.embeddings,\n",
        "        )\n",
        "\n",
        "        # Save the vector database locally\n",
        "        vector_database.save_local(DB_FAISS_PATH)\n",
        "\n",
        "    # Function to remove all files in the DATA_DIR directory\n",
        "    def remove_all_files(self, data_dir):\n",
        "        \"\"\"\n",
        "        Remove all files in the specified directory.\n",
        "\n",
        "        Args:\n",
        "            data_dir (str): The directory from which files should be removed.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            file_list = os.listdir(data_dir)\n",
        "            for file_name in file_list:\n",
        "                file_path = os.path.join(data_dir, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    os.remove(file_path)\n",
        "            st.sidebar.success(f\"All files in {data_dir} have been removed.\")\n",
        "        except Exception as e:\n",
        "            st.sidebar.error(f\"An error occurred while removing files: {str(e)}\")\n",
        "\n",
        "    # Function to load the language model\n",
        "    def load_model(self, max_new_tokens=1000, temperature=0.7, n_ctx=2048):\n",
        "        \"\"\"\n",
        "        Load a language model for generating responses in a conversation based on selected language.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): The path to the language model file.\n",
        "            max_new_tokens (int): The maximum number of tokens in generated responses.\n",
        "            temperature (float): The temperature parameter for response generation.\n",
        "            n_ctx (int): The context window size for the model.\n",
        "\n",
        "        Returns:\n",
        "            LlamaCpp: An instance of LlamaCpp, a language model for conversation.\n",
        "        \"\"\"\n",
        "        if self.selected_language == \"English\":\n",
        "            model_path = ENGLISH_MODEL_PATH\n",
        "        elif self.selected_language == \"German\":\n",
        "            model_path = GERMAN_MODEL_PATH\n",
        "        else:\n",
        "            raise ValueError(\"Invalid language selection\")\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"No model file found at {model_path}\")\n",
        "\n",
        "        callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "\n",
        "        llm = LlamaCpp(\n",
        "            model_path=model_path,\n",
        "            n_ctx=n_ctx,\n",
        "            max_tokens=max_new_tokens,\n",
        "            temperature=temperature,\n",
        "            callback_manager=callback_manager,\n",
        "            verbose=True,\n",
        "        )\n",
        "\n",
        "        return llm\n",
        "\n",
        "    # Function to create HuggingFace embeddings\n",
        "    def create_huggingface_embeddings(self, model_name=MODEL_EMBEDDING_PATH):\n",
        "        \"\"\"\n",
        "        Create HuggingFace embeddings for a given model name.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): The name of the HuggingFace model.\n",
        "\n",
        "        Returns:\n",
        "            HuggingFaceEmbeddings: An instance of HuggingFaceEmbeddings.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return HuggingFaceEmbeddings(\n",
        "                model_name=model_name,\n",
        "                model_kwargs={\"device\": \"cpu\"},\n",
        "                encode_kwargs = {'normalize_embeddings': False},\n",
        "            )\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to load embeddings with model name {model_name}: {str(e)}\")\n",
        "\n",
        "    # Function to create a QA bot\n",
        "    def create_qa_bot(self):\n",
        "        \"\"\"\n",
        "        Create a Question-Answering (QA) bot using the specified components and configurations.\n",
        "\n",
        "        Returns:\n",
        "        - chain (ConversationalRetrievalChain): A configured QA bot instance ready for use.\n",
        "        \"\"\"\n",
        "        vector_store = FAISS.load_local(folder_path=DB_FAISS_PATH, embeddings=self.embeddings)\n",
        "\n",
        "        # Define templates for question-answering prompts based on language\n",
        "        if self.selected_language == \"English\":\n",
        "            template = \"\"\"Use the following context to answer the question at the end.\n",
        "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "            Use a maximum of three sentences and keep the answer concise.\n",
        "            {context}\n",
        "            Question: {question}\n",
        "            Helpful Answer:\"\"\"\n",
        "        elif self.selected_language == \"German\":\n",
        "            template = \"\"\"Verwenden Sie den folgenden Kontext, um die Frage am Ende zu beantworten.\n",
        "            Wenn Sie die Antwort nicht wissen, geben Sie einfach an, dass Sie es nicht wissen, und versuchen Sie nicht, eine Antwort zu erfinden.\n",
        "            Verwenden Sie maximal drei Sätze und halten Sie die Antwort prägnant.\n",
        "            {context}\n",
        "            Frage: {question}\n",
        "            Hilfreiche Antwort:\"\"\"\n",
        "        else:\n",
        "            raise ValueError(\"Invalid language selection\")\n",
        "\n",
        "        QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
        "\n",
        "        # Initialize a conversation buffer memory\n",
        "        memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "        # Create a ConversationalRetrievalChain for handling conversations\n",
        "        chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm=self.llm,\n",
        "            chain_type='stuff',\n",
        "            retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}),\n",
        "            memory=memory,\n",
        "            # return_source_documents=True,\n",
        "            combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        "        )\n",
        "        return chain\n",
        "\n",
        "    # Function to handle conversation chat\n",
        "    def conversation_chat(self, query):\n",
        "        \"\"\"\n",
        "        Handle a conversation query and generate a response.\n",
        "\n",
        "        Args:\n",
        "            query (str): The user's query.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated response.\n",
        "        \"\"\"\n",
        "        chain = self.create_qa_bot()\n",
        "        result = chain({\"question\": query, \"chat_history\": st.session_state['history']})\n",
        "        st.session_state['history'].append((query, result[\"answer\"]))\n",
        "        return result[\"answer\"]\n",
        "\n",
        "    # Initialize session state\n",
        "    def initialize_session_state(self):\n",
        "        \"\"\"\n",
        "        Initialize session-specific variables.\n",
        "        \"\"\"\n",
        "        if 'history' not in st.session_state:\n",
        "            st.session_state['history'] = []\n",
        "\n",
        "        if 'generated' not in st.session_state:\n",
        "            st.session_state['generated'] = []\n",
        "\n",
        "        if 'past' not in st.session_state:\n",
        "            st.session_state['past'] = []\n",
        "\n",
        "    # Display chat history and handle user input\n",
        "    def display_chat_history(self):\n",
        "        \"\"\"\n",
        "        Display the chat history and handle user input for the Streamlit app.\n",
        "        \"\"\"\n",
        "        reply_container = st.container()\n",
        "        container = st.container()\n",
        "\n",
        "        with container:\n",
        "            with st.form(key='my_form', clear_on_submit=True):\n",
        "                user_input = st.text_input(\"Question:\", placeholder=\"Ask Here !\", key='input')\n",
        "                submit_button = st.form_submit_button(label='Send')\n",
        "\n",
        "            if submit_button and user_input:\n",
        "                output = self.conversation_chat(user_input)\n",
        "\n",
        "                st.session_state['past'].append(user_input)\n",
        "                st.session_state['generated'].append(output)\n",
        "\n",
        "        if st.session_state['generated']:\n",
        "            with reply_container:\n",
        "                for i in range(len(st.session_state['generated'])):\n",
        "                    message(st.session_state[\"past\"][i], is_user=True, key=str(i) + '_user', avatar_style=\"thumbs\")\n",
        "                    message(st.session_state[\"generated\"][i], key=str(i), avatar_style=\"fun-emoji\")\n",
        "\n",
        "    def generate_summarization(self, txt):\n",
        "        \"\"\"\n",
        "        Generate a summarization for the given text.\n",
        "\n",
        "        Args:\n",
        "            txt (str): The input text to be summarized.\n",
        "\n",
        "        Returns:\n",
        "            str: The generated summarization.\n",
        "        \"\"\"\n",
        "        # Split text\n",
        "        text_splitter = CharacterTextSplitter()\n",
        "        texts = text_splitter.split_text(txt)\n",
        "\n",
        "        # Create multiple documents from text\n",
        "        docs = [Document(page_content=t) for t in texts]\n",
        "\n",
        "        # Text summarization\n",
        "        chain = load_summarize_chain(self.llm, chain_type='map_reduce')\n",
        "        summarized_texts = chain.run(docs)  # Assumes chain.run returns a list of summarized texts\n",
        "\n",
        "        return summarized_texts\n",
        "\n",
        "    def display_summarization_results(self):\n",
        "        \"\"\"\n",
        "        Display the summarization results.\n",
        "        \"\"\"\n",
        "\n",
        "        # Text input\n",
        "        txt_input = st.text_area(\"Enter the text to summarize:\", \"\", height=200)\n",
        "\n",
        "        # Form to accept user's text input for summarization\n",
        "        with st.form(\"summarize_form\", clear_on_submit=True):\n",
        "            submitted = st.form_submit_button(\"Summarize\")\n",
        "\n",
        "            if submitted:\n",
        "                # Generate the summarization\n",
        "                response = self.generate_summarization(txt_input)\n",
        "                st.subheader(\"Summarized Text\")\n",
        "                st.write(response)\n",
        "    # Streamlit app setup\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Streamlit application entry point.\n",
        "        \"\"\"\n",
        "\n",
        "        # Language selection\n",
        "        st.sidebar.header(\"Select Language / Sprache auswählen\")\n",
        "        self.selected_language = st.sidebar.selectbox(\"Choose a language / Wählen Sie eine Sprache aus:\", [\"English\", \"German\"])\n",
        "\n",
        "        # Change UI text based on selected language\n",
        "        if self.selected_language == \"English\":\n",
        "            ui_texts = {\n",
        "                \"title_document_qa_bot\": \"Document QA Bot\",\n",
        "                \"title_text_summarization\": \"Text Summarization\",\n",
        "                \"upload_section\": \"Upload Documents\",\n",
        "                \"ocr_section\": \"OCR for Images\",\n",
        "                \"audio_section\": \"Upload Audio Files and Transcribe\",\n",
        "                \"html_section\": \"Import HTML\",\n",
        "                \"youtube_section\": \"YouTube Video\",\n",
        "                \"youtube_url\": \"Enter YouTube Video URL\",\n",
        "                \"db_section\": \"Create Vector Database\",\n",
        "                \"remove_section\": \"Remove Files\",\n",
        "                \"task_section\": \"Choose Task\",\n",
        "                \"task_option_chatbot\": \"Chatbot\",\n",
        "                \"task_option_summarization\": \"Summarization\",\n",
        "                \"transcribe_button\": \"Transcribe Video\",\n",
        "                \"upload_files_label\": \"Upload PDF, MD, TXT, or DOCX files\",\n",
        "                \"upload_images_label\": \"Upload image files (PNG, JPG, JPEG)\",\n",
        "                \"convert_html_button_label\": \"Convert HTML\",\n",
        "                \"create_db_button_label\": \"Create Database\",\n",
        "                \"remove_files_button_label\": \"Remove ALL Files\",\n",
        "            }\n",
        "        elif self.selected_language == \"German\":\n",
        "            ui_texts = {\n",
        "                \"title_document_qa_bot\": \"Dokumenten-Frage-Antwort-Bot\",\n",
        "                \"title_text_summarization\": \"Textzusammenfassung\",\n",
        "                \"upload_section\": \"Dokumente hochladen\",\n",
        "                \"ocr_section\": \"OCR für Bilder\",\n",
        "                \"audio_section\": \"Audiodateien hochladen und transkribieren\",\n",
        "                \"html_section\": \"HTML importieren\",\n",
        "                \"youtube_section\": \"YouTube-Video\",\n",
        "                \"youtube_url\": \"Geben Sie die YouTube-Video-URL ein\",\n",
        "                \"db_section\": \"Vektordatenbank erstellen\",\n",
        "                \"remove_section\": \"Dateien entfernen\",\n",
        "                \"task_section\": \"Aufgabe auswählen\",\n",
        "                \"task_option_chatbot\": \"Chatbot\",\n",
        "                \"task_option_summarization\": \"Zusammenfassung\",\n",
        "                \"transcribe_button\": \"Video transkribieren\",\n",
        "                \"upload_files_label\": \"PDF-, MD-, TXT- oder DOCX-Dateien hochladen\",\n",
        "                \"upload_images_label\": \"Bilddateien hochladen (PNG, JPG, JPEG)\",\n",
        "                \"convert_html_button_label\": \"HTML konvertieren\",\n",
        "                \"create_db_button_label\": \"Datenbank erstellen\",\n",
        "                \"remove_files_button_label\": \"Alle Dateien entfernen\",\n",
        "            }\n",
        "        else:\n",
        "            raise ValueError(\"Invalid language selection\")\n",
        "\n",
        "        # Choose Task\n",
        "        st.sidebar.header(ui_texts[\"task_section\"])\n",
        "        self.selected_task = st.sidebar.radio(\"Select a task / Wählen Sie eine Aufgabe aus:\", [ui_texts[\"task_option_chatbot\"], ui_texts[\"task_option_summarization\"]])\n",
        "\n",
        "        if self.selected_task == ui_texts[\"task_option_chatbot\"]:\n",
        "\n",
        "            st.title(ui_texts[\"title_document_qa_bot\"])\n",
        "\n",
        "            # Section 1: Upload Documents\n",
        "            st.sidebar.header(ui_texts[\"upload_section\"])\n",
        "            uploaded_files = st.sidebar.file_uploader(ui_texts[\"upload_files_label\"], accept_multiple_files=True)\n",
        "\n",
        "            if uploaded_files:\n",
        "                for uploaded_file in uploaded_files:\n",
        "                    self.save_uploaded_file(uploaded_file)\n",
        "\n",
        "            # Section 2: OCR for Images\n",
        "            st.sidebar.header(ui_texts[\"ocr_section\"])\n",
        "            uploaded_images = st.sidebar.file_uploader(ui_texts[\"upload_images_label\"], accept_multiple_files=True)\n",
        "\n",
        "            if uploaded_images:\n",
        "                for uploaded_image in uploaded_images:\n",
        "                    self.save_uploaded_file(uploaded_image)\n",
        "                    if uploaded_image.name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        ocr_result = self.ocr_and_save_text(os.path.join(DATA_DIR, uploaded_image.name))\n",
        "                        if ocr_result:\n",
        "                            st.sidebar.success(f\"OCR performed on '{uploaded_image.name}' and text saved as '{os.path.basename(ocr_result)}'\")\n",
        "\n",
        "            # Section 3: Upload Audio Files and Transcribe\n",
        "            st.sidebar.header(ui_texts[\"audio_section\"])\n",
        "            uploaded_audio_files = st.sidebar.file_uploader(\"Upload audio files (MP3, WAV)\", accept_multiple_files=True)\n",
        "\n",
        "            if uploaded_audio_files:\n",
        "                for uploaded_audio_file in uploaded_audio_files:\n",
        "                    # Check if the uploaded file is an audio file\n",
        "                    if uploaded_audio_file.name.lower().endswith(('.mp3', '.wav')):\n",
        "                        # Transcribe and save the audio file\n",
        "                        transcription_result = self.transcribe_audio_file(uploaded_audio_file)\n",
        "                        if transcription_result:\n",
        "                            st.sidebar.success(f\"Audio transcription saved as {transcription_result}\")\n",
        "\n",
        "            # Section 4: Import HTML\n",
        "            st.sidebar.header(ui_texts[\"html_section\"])\n",
        "            url_input = st.sidebar.text_input(\"Enter URL(s) for HTML documents (separated by commas)\")\n",
        "\n",
        "            if st.sidebar.button(ui_texts[\"convert_html_button_label\"]) and url_input:\n",
        "                urls = url_input.split(\",\")\n",
        "                for url in urls:\n",
        "                    self.save_html_from_url(url.strip(), DATA_DIR)\n",
        "                    st.sidebar.success(f\"HTML content from {url} saved locally.\")\n",
        "\n",
        "            # Section 5: Transcribe YouTube Video\n",
        "            st.sidebar.header(ui_texts[\"youtube_section\"])\n",
        "            youtube_url = st.sidebar.text_input(\"Enter YouTube Video URL\")\n",
        "\n",
        "            if st.sidebar.button(ui_texts[\"transcribe_button\"]) and youtube_url:\n",
        "                transcribed_file = self.transcribe_youtube_video(youtube_url)\n",
        "                if transcribed_file:\n",
        "                    st.sidebar.success(f\"Transcription saved as {transcribed_file}\")\n",
        "\n",
        "            # Section 6: Create Vector Database\n",
        "            st.sidebar.header(ui_texts[\"db_section\"])\n",
        "            if st.sidebar.button(ui_texts[\"create_db_button_label\"]):\n",
        "                self.create_vector_database(DATA_DIR)\n",
        "                st.sidebar.success(\"Vector database created.\")\n",
        "\n",
        "            # Section 7: Remove All Files\n",
        "            st.sidebar.header(ui_texts[\"remove_section\"])\n",
        "            if st.sidebar.button(ui_texts[\"remove_files_button_label\"]):\n",
        "                self.remove_all_files(DATA_DIR)\n",
        "\n",
        "            # Run the chatbot\n",
        "            self.initialize_session_state()\n",
        "            self.display_chat_history()\n",
        "\n",
        "        elif self.selected_task == ui_texts[\"task_option_summarization\"]:\n",
        "\n",
        "            st.title(ui_texts[\"title_text_summarization\"])\n",
        "\n",
        "            # Run the summarization function\n",
        "            self.display_summarization_results()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app = DocumentQAApp()\n",
        "    app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9Ur_v3RV5Dj",
        "outputId": "ace4f97b-ce45-48e9-c70b-a9d3444c3625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "AevuewgnXcgA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}